---
title: "Time Series CV - Arima Models"
author: "Tiago Souza"
date: "3/31/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidymodels)
library(lubridate)
library(magrittr)

library(httr)
library(timetk)
```

## Step 0: Parameters
```{r, parameters}
# Number of periods to forecast
forecast_length <- 20 
# Number of periods in test sample
test_size <- 24
# Initial number of periods included in a split
initial_periods <- 36
# Number of splits in output
splits_number <- 10

```


## Step 1: Download and tidy data

In this example we will use Manufacturing production data from Brazil.

Notice below that codes appear as variable names, the first row of the data frame contains information about the variables (not data itself), and all variables are character.

```{r, data}

data_links <- list(
  manufacturing = "https://apisidra.ibge.gov.br/values/t/3653/v/3134/c544/129316/p/all/n1/all",
  retail = "https://apisidra.ibge.gov.br/values/t/3417/v/1186/c11046/40312/p/all/n1/all")

download_data <- function(url) {
  data <- GET(url = url) %>% 
    content(as = "parsed") %>% 
    map_dfr(., ~.)
}

data <- map_dfr(data_links, download_data, .id = "variable") %>% 
  
  filter(NC == "1") %>% 
  
  transmute(
    variable = variable,
    date = ymd(paste0(D3C,"01")),
    value = as.numeric(V)) %>% 
  
  group_by(variable) %>% 
  
  mutate(value = value / lag(value, n=1) - 1) %>% 
  
  drop_na() %>% 
  
  ungroup()

print(data)

data %>% 
  ggplot(aes(x = date, y = value, color = variable)) + 
  geom_line() + 
  facet_grid(variable ~ .)
```


## Step 2: Define models

Here we define a set of models and the names of their respective recipes. What defines one specification is a pair model-recipe. 

```{r def-models}

seasonal_per <- timetk::tk_get_frequency(data %>% 
                                           filter(variable == "manufacturing") %>% 
                                           pull(date),
                                         period = "auto",
                                         message = FALSE)

define_model <- function(p, d, q, P, D, Q, seasonal_per = seasonal_per){
    
    model <- modeltime::arima_reg(
      seasonal_period = seasonal_per,
      non_seasonal_ar = p,
      non_seasonal_differences = d,
      non_seasonal_ma = q,
      seasonal_ar = P,
      seasonal_differences = D,
      seasonal_ma = Q
    ) %>% 
      
      set_engine("arima") %>% 
      
      return(model)
    
  }
  
  grid_arima <- expand_grid(p = 0:4,
                            d = 0,
                            q = 0:1,
                            P = 0,
                            D = 0,
                            Q = 0)
  
  models_def <- grid_arima %>% 
    
    mutate(model_arima = pmap(list(p,d,q,P,D,Q), define_model))

head(models_def)

```

## Step 3: Split Data - train/test

Now we define train and test samples based on one year and create a data frame to store forecasts.

To clarify:

  * **data**: complete set of data
  * **data_train**: subset of 'data' to proceed with estimation via cross-validation
  * **data_test**: subset 'data' to test performance at the end
  * **data_extended**: original 'data' with the future periods appended at the end
  * **data_future**: just the future periods
  
```{r, data-split}
# Worked on both
data_complete <- data %>% 
  
  group_nest(variable) %>% 
  
  mutate(
    data_split = map(data, ~ .x %>% time_series_split(
                                      date_var = date,
                                      initial = initial_periods,
                                      assess = test_size,
                                      lag = lag_max,
                                      cumulative = TRUE,
                                      slice = 1)),
    data_train = map(data_split, ~ .x %>% training()),
    data_test = map(data_split, ~ .x %>% testing()),
    data_extended = map(data, ~ .x %>% timetk::future_frame(
                                        .date_var = date,
                                        .length_out = forecast_length,
                                        .bind_data = TRUE)),
    data_forecast = map(data_extended, ~ .x %>% filter(is.na(value)))
    ) %>% 
  
  select(-data_split)

print(data_complete)
```


## Step 4: Split Data - CV

Remember that a recipe is defined by an equation and a data set. Hence, before creating recipes, we must split the training data.
```{r, data-cv}
# Worked on both
data_splits <- data_complete %>% 
  
  transmute(
    variable = variable,
    split = map(data_train, ~ .x %>% time_series_cv(
                                      date_var = date,
                                      initial = initial_periods,
                                      assess = forecast_length,
                                      lag = lag_max,
                                      cumulative = TRUE,
                                      slice_limit = splits_number))) %>% 
  
  unnest(split) %>% 
  
  rename(split_id = id, 
         split = splits)

head(data_splits)
```

## Step 5: Complete tibble with all components

```{r, models-components}
models_components <- models_def %>% 
  
  expand_grid(data_splits) %>% 
  
  mutate(
    recipe = map(split, ~ recipe(value ~ date, data = training(.x))),
    workflow = map2(model_arima, recipe, ~ workflow() %>% 
                                            add_model(.x) %>% 
                                            add_recipe(.y))
    ) %>% 
  
  select(-recipe)

head(models_components)
```

## Step 6: Fitting models to all splits

```{r, models-fit, cache=TRUE}
models_fitted <- models_components %>% 
  
  mutate(fit = map2(workflow, split, ~ fit(.x, data = training(.y)))) %>% 
  
  select(-workflow)

head(models_fitted)
```
## Step 7: Calibrated data for test sample

```{r, data-calibr}
data_calibr <- models_fitted %>% 
  
  mutate(
    fitted_recipe = map(fit, ~ extract_recipe(.x)),
    fitted_model = map(fit, ~ extract_fit_parsnip(.x)),
    data = map(split, ~ testing(.x)),
    data_test = map2(fitted_recipe, data, ~ bake(.x, .y)),
    pred = map2(fitted_model, data_test, ~ predict(.x, new_data = .y %>% select(-value))),
    across(c(data, pred), ~ map(.x, function(x) slice_tail(x, n = forecast_length))),
    data = map2(data, pred, ~ .x %>% bind_cols(.y))
  ) %>% 
  
  select(variable,
         model_id,
         recipe_id,
         split_id,
         data) %>% 
  
  unnest(data)

head(data_calibr)
```
## Step 8: Error metrics

```{r, forecast-errors}
error_metrics <- data_calibr %>% 
  
  group_by(variable, model_id, recipe_id, split_id) %>% 
  
  metrics(value, .pred) %>% 
  
  group_by(variable, model_id, recipe_id, .metric) %>% 
  
  summarize(mean_error = mean(.estimate), .groups = "drop_last")

head(error_metrics)
```

## Step 9: Best model

The metric of choice will be "MAE".

```{r, best-model}
best_model <- error_metrics %>% 
  
  filter(.metric == "mae") %>%

  group_by(variable) %>%

  filter(mean_error == min(mean_error)) %>%

  select(variable, model_id, recipe_id)

head(best_model)
```

## Step 10: Refit best models

```{r, refit-models}
refit_models <- best_model %>% 
  
  left_join(data_complete, by = "variable") %>% 
  
  left_join(models_def, by = c("model_id", "recipe_id")) %>% 
  
  mutate(
    recipe = map2(data_train, recipe_id, ~ create_recipe(.x, .y)),
    workflow = map2(workflow, recipe, ~ .x %>% add_recipe(.y)),
    fit = map2(workflow, data_train, ~ fit(.x, data = .y)),
    fitted_recipe = map(fit, ~ extract_recipe(.x)),
    fitted_model = map(fit, ~ extract_fit_parsnip(.x))
  ) %>%
  
  ungroup() 

head(refit_models)
```

## Step 11: Performance with respect to test data

```{r, performance-test}
data_perf <- refit_models %>% 
  
  select(variable,
         data_test,
         fitted_recipe,
         fitted_model) %>% 
  
  mutate(
    data_test = map2(fitted_recipe, data_test, ~ bake(.x, .y)),
    pred = map2(fitted_model, data_test, ~ predict(.x, new_data = .y %>% select(-value))),
    across(c(data_test, pred), ~ map(.x, function(x) slice_tail(x, n = forecast_length))),
    data_test = map2(data_test, pred, ~ .x %>% select(value) %>%  bind_cols(.y))
  ) %>% 
  
  select(
    variable,
    data_test
  ) %>% 
  
  unnest(data_test)

head(data_perf)
```
```{r, chart-performance}
data_perf %>% 
  
  ggplot(aes(x=value, y=.pred))+
    geom_point()+ 
    geom_smooth(method = "lm", formula = y ~ x)+
    facet_grid(variable ~ .)
```


## Step 11: Forecasts

Now we turn to forecasting the future, and for that we will need a recursive approach. This is needed since to forecast $n$ periods ahead, given the existence of lag variables in the models, it is needed to have the forecast for the $n-1$ previous periods.

```{r, forecasts}
check_forecast <- function(df_refit) {
  
  check <- df_refit %>% 
  
  select(data_forecast) %>% 
  
  transmute(check = map(data_forecast, ~ .x %>% 
                       select(value) %>% 
                       anyNA()),
            check = as.logical(check)) %>% 
  
  use_series(check) %>% 
  
  any()
  
  return(check)
  
}

final <- refit_models

while(check_forecast(final)) {

final <- final %>% 
  
  mutate(
    pred = map2(fitted_recipe, data_extended, ~ bake(.x, .y) %>% slice_tail(n = 1)),
    pred = map(pred, ~ .x %>% filter(is.na(value)) %>% select(-value)),
    pred = map2(fitted_model, pred, ~ predict(.x, new_data = .y)),
    pred = map2(data_forecast, pred, 
                ~ .x %>% filter(is.na(value)) %>% 
                  mutate(value = if_else(date == min(date), 
                                         .y %>% use_series(.pred),
                                         value))),
    data_forecast = map2(data_forecast, pred, ~ .x %>% rows_update(.y, by = "date")),
    data_extended = map2(data_extended, pred, ~ .x %>% rows_update(.y, by = "date"))
    ) 
}
  
final <- final %>% 
  select(variable,
         data,
         data_forecast)

head(final)
```

```{r, chart-forecast}
plot_final <- final %>% 
  
  select(-data_forecast) %>% 
  
  unnest(data) %>% 
  
  mutate(data = "past") %>% 
  
  bind_rows(final %>% 
              select(-data) %>% 
              unnest(data_forecast) %>% 
              mutate(data = "future")) 

plot_final %>% 
  
  ggplot(aes(x = date, y = value, color = data)) +
    geom_line() +
    facet_grid(. ~ variable)
```

